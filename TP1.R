###########################################
# TP 1 - J√©r√¥me CR√âTIEN - Florent RENUCCI #
# 25 septembre - pour le 15 octobre		  #
###########################################


###########################
# exemples d'instructions #
###########################
# iris
# ncol(iris)
# dim(iris)
# names(iris)
# plot(iris)
# plot(iris,col=c("blue","red","green")[iris$Species])
# mean(iris)
# sd(iris)
# iris[1,]
# iris[,5]
# iris$Species
# tapply(iris$Sepal.Width,iris$Species,mean)
# tapply(iris$Species,iris$Species,length)


#############################################
# Analyse discriminante lin√©aire pr√©dictive #
#############################################
rm(list=ls())

#-----------
# Question 1
#-----------
library(MASS)
#-----------
# Question 2
#-----------
help(lda)
model = lda(Species~.,data=iris)
#-----------
# Question 3
#-----------
model
# Prior : il s'agit des probabilit√©s a priori d'appartenance √† chaque classe (dans une approche bay√©sienne). Ici, on n'a pas renseign√© d'a priori. La fonciton consid√®re donc que l'appartenance √† chaque classe est a priori √©quiprobable (3 classes => p=1/3).
# Group means : renvoie la moyenne de chaque variable, par classe
# Coefficients of linear discriminants : renvoie les coefficients des vecteurs r√©alisant l'analyse discriminante lin√©aire
# Proportion of trace : renvoie la proportion de la trace (variabilit√©) capt√©e par chaque direction
# Le crit√®re de d√©cision retenu dans le cadre de l'analyse discriminante lin√©aire est la maximisation de la variance inter, en ajustant des hyperplans pour classifier (s√©parer) les observations.

#-----------
# Question 4
#-----------
plot(model)
# plot(model) permet d'observer la r√©partition des observations dans le plan de projection (LD1,LD2) qui maximise la variabilit√©. On constate que les trois classes sont assez bien r√©parties. En particulier, les setosa sont bien distinctes des deux autres groupes.
# Ceci confirme les valeurs de "proportion of trace" : le 1er vecteur, m√™me seul, permettrait quand m√™me de bien s√©parer les groupes.

#-----------
# Question 5
#-----------
learning_indices = sample(nrow(iris),0.80*nrow(iris))
# on choisit 80% des lignes, au hasard, qui formeront le learning set

learning_set = iris[learning_indices,]
test_set = iris[-learning_indices,]
# le reste des lignes forment la base de test


#-----------
# Question 6
#-----------
lda_model = lda(Species~.,data=learning_set)
prediction_learning = predict(lda_model,learning_set)
#-----------
# Question 7
#-----------
ConfusionMatrix_learning = table(prediction_learning$class,learning_set$Species)
# Matrice de confusion sur la base d'apprentissage :

# /!\ On ne sait pas a priori, sans regarder l'aide, si on a la confusion matrix ou sa transpos√©e
# ICI : on a la pr√©diction en ligne et la cible en colonne
# Matrice de confusion sur la base d'apprentissage :
ConfusionMatrix_learning
# Erreur de pr√©diction sur la base d'apprentissage :
erreur= 1-sum(diag(ConfusionMatrix_learning))/sum(ConfusionMatrix_learning)

# C'est proche de 0 : c'est une condition n√©cessaire non suffisante de fiabilit√© du mod√®le : la base d'apprentissage permet "de se pr√©dire elle-m√™me", ce qui ne signifie pas forc√©ment qu'elle peut pr√©dire les classes d'individus ext√©rieurs. 

#-----------
# Question 8
#-----------
prediction_test = predict(lda_model,test_set)
ConfusionMatrix_test = table(prediction_test$class,test_set$Species)
# Matrice de confusion sur la base de test :
ConfusionMatrix_test
# Erreur de pr√©diction sur la base de test :
1-sum(diag(ConfusionMatrix_test))/sum(ConfusionMatrix_test)
# REMARQUES :
# L'erreur de pr√©diction (en proportion) est comparable pour la base de test et la base d'apprentissage.
# On remarque m√™me que l'erreur de pr√©diction est souvent plus faible sur la base de test que sur la base d'apprentissage.
# Ceci n'est pas surprenant : faire des erreurs sur la base d'apprentissage est une bonne chose pour √©viter le sur-apprentissage (overfitting).
#-----------
# Question 9
#-----------
# REMARQUES :
# On remarque qu'il ne suffit que de peu d'individus dans la base d'apprentissage pour avoir une erreur de pr√©diction tr√®s faible : m√™me 30% ou 20% des observations dans la base d'apprentissage permet d'identifier de mani√®re fiable les classes des individus de la base de test. Par ailleurs, il y a rarement des erreurs.
# Apr√®s plusieurs tests, on constate que le classiffieur ne se trompe que tr√®s rarement (entre 0 et 2 fois selon la base de test)
# En particulier, il ne se trompe jamais pour les setosas, qui sont (comme on l'a vu plus haut) bien s√©par√©s (g√©om√©triquement) des deux autres groupes.
# En somme, les donn√©es utilis√©es ici sont particuli√®rement propres et adapt√©es √† la m√©thode utilis√©e.

################################################
# Analyse discriminante quadratique pr√©dictive #
################################################

#-----------
# Question 1
#-----------
help(qda)
model_qda = qda(Species~.,data=iris)
prediction_qda = predict(model_qda,iris)
ConfusionMatrix_qda = table(prediction_qda$class,iris$Species)
# Matrice de confusion QDA :
ConfusionMatrix_qda
# Erreur de pr√©diction QDA :
1-sum(diag(ConfusionMatrix_qda))/sum(ConfusionMatrix_qda)

#-----------
# Question 2
#-----------
# RETOUR AU LDA (pour comparaison) :
#-----------------------------------
# prediction LDA :
prediction = predict(model,iris)
ConfusionMatrix_lda  = table(prediction$class,iris$Species)
# Matrice de confusion LDA :
ConfusionMatrix_lda
# Erreur de pr√©diction LDA :
1-sum(diag(ConfusionMatrix_lda))/sum(ConfusionMatrix_lda)
# REMARQUES :
# Si on effectue une LDA ou une QDA sur l'ensemble des donn√©es, on obtient la m√™me matrice de confusion.
# Pour comparer les deux m√©thodes, nous allons donc tester leurs r√©sultats plusieurs fois sur des jeux d'apprentissages / test choisis al√©atoirement.
# On effectue 1000 tests et on note √† chaque fois le nombre d'erreurs de classification pour chaque m√©thode.
# (ceci est fait par la portion de code ci-dessous :)
#-------------------------------------------------------
# COMPARAISON LDA/QDA sur des bases apprentissage/test :
#-------------------------------------------------------
N = 1000
lda_errors = rep(0,0.20*nrow(iris))
qda_errors = rep(0,0.20*nrow(iris))
for (k in 1:N) {
	# sets :
	learning_indices = sample(nrow(iris),0.80*nrow(iris))
	learning_set = iris[learning_indices,]
	test_set = iris[-learning_indices,]
	# LDA model :
	lda_model = lda(Species~.,data=learning_set)
	lda_prediction = predict(lda_model,test_set)
	lda_ConfusionMatrix = table(lda_prediction$class,test_set$Species)
	lda_errors[sum(lda_ConfusionMatrix)-sum(diag(lda_ConfusionMatrix))] = lda_errors[sum(lda_ConfusionMatrix)-sum(diag(lda_ConfusionMatrix))] + 1
	# QDA model :
	qda_model = qda(Species~.,data=learning_set)
	qda_prediction = predict(qda_model,test_set)
	qda_ConfusionMatrix = table(qda_prediction$class,test_set$Species)
	qda_errors[sum(qda_ConfusionMatrix)-sum(diag(qda_ConfusionMatrix))] = qda_errors[sum(qda_ConfusionMatrix)-sum(diag(qda_ConfusionMatrix))] + 1
}
plot(lda_errors,type="l",col="red")
lines(qda_errors,col="blue")
title(main="LDA (rouge) / QDA (bleu) : nombre d'erreurs")
legend(c("LDA","QDA"),col=c("red","blue"));
# REMARQUES :
# Dans l'ensemble (sur les 1000 tests r√©alis√©s), la LDA donne de meilleurs r√©sultats que la QDA : pour un nombre d'erreurs donn√©, il y a eu plus de r√©alisations pour la QDA que pour la LDA.
# Ainsi, il semblerait que la g√©om√©trie des donn√©es soit plut√¥t adapt√©e √† un mod√®le lin√©aire que quadratique.
# La comparaison des deux m√©thodes se limite bien s√ªr aux r√©sultats obtenus sur les donn√©es √©tudi√©es.

#########################
# R√©gression logistique #
#########################
rm(list=ls())

#-----------
# Question 1
#-----------

file = "D:/frenucci/Dropbox/DonnÈes/Scolaire/cours/3A/Statistiques et Data-Mining/TP/TP1/SAHeart.txt"

data = read.table(file,sep=",",head=T,row.names=1)
data = data[,-6]
data

# A retrospective sample of males in a heart-disease high-risk region of the Western Cape, South Africa. There are roughly two controls per case of CHD. Many of the CHD positive men have undergone blood pressure reduction treatment and other programs to reduce their risk factors after their CHD event. In some cases the measurements were made after these treatments. These data are taken from a larger dataset, described in  Rousseauw et al, 1983, South African Medical Journal.

# Variables explicatives :
# sbp  	    systolic blood pressure
# tobacco   cumulative tobacco (kg)
# ldl		low densiity lipoprotein cholesterol
# adiposity 
# famhist	family history of heart disease (Present, Absent)
# typea		type-A behavior
# obesity	
# alcohol	current alcohol consumption
# age		age at onset
# chd		response, coronary heart disease

#-----------
# Question 2
#-----------
pairs(data,pch=22,bg=c("red","blue")[unclass(factor(data[,"chd"]))])

# la derni√®re ligne de graphiques nous permet de savoir √† quoi correspondent les couleurs¬†: les rouges sont les malades.
# On constate que sur tous les graphiques, tous les points sont assez √©loign√©s pour qu‚Äôil n‚Äôy ait pas un unique facteur explicatif suffisant pour expliquer la maladie.
# Causes visibles √† l'oeil nu : grands fumeurs, et gens √† forts taux de ldl.

#-----------
# Question 3
#-----------
help(glm)
fit = glm(data$chd~.,data=data,family=binomial)
summary(fit)
#-----------
# Question 4
#-----------
classification = predict.glm(fit,data,type="response")
# classification = predict(fit,data,type="response")
classification = 1*(classification>0.5)
# pour avoir des 0 et 1 √† la place de TRUE et FALSE
CM = table(classification,data$chd)
CM
# on peut aussi calculer l'erreur sur la base de test, on trouve 26%
erreur=1-sum(diag(CM))/sum(CM)
# les faux positifs sont au nombre de 77 (√©l√©ment (1,2) de la matrice de confusion), les faux n√©gatifs sont 46 (√©l√©ment (2,1) de la matrice de confusion)
fauxneg=CM[1,2]/sum(CM)
fauxneg
# 17% de faux n√©gatifs
fauxpos=CM[2,1]/sum(CM)
fauxpos
# 10% de faux positifs
# Dans l'ensemble, ces r√©sultats ne sont pas tr√®s satisfaisants.

#-----------
# Question 5
#-----------

learning_indices = sample(nrow(data),0.75*nrow(data))
# on choisit 75% des lignes, au hasard, qui formeront le learning set
learning_set = data[learning_indices,]
testing_set = data[-learning_indices,]

lda_model = lda(chd~.,data=learning_set)
prediction_learning = predict(lda_model,learning_set)
CM_learning = table(prediction_learning$class,learning_set$chd)

erreur_learning=1-sum(diag(CM_learning))/sum(CM_learning)
fauxneg_learning=CM_learning[1,2]/sum(CM_learning)
fauxpos_learning=CM_learning[2,1]/sum(CM_learning)

# beaucoup d'erreurs : autour de 25% au total, en r√©p√©tant le test plusieurs fois et en changeant les bases d'apprentissage et de test.

prediction_test = predict(lda_model,testing_set)
CM_test = table(prediction_test$class,testing_set$chd)

erreur_test=1-sum(diag(CM_test))/sum(CM_test)
fauxneg_test=CM_test[1,2]/sum(CM_test)
fauxpos_test=CM_test[2,1]/sum(CM_test)

# On pouvait s'attendre √† de tels r√©sultats : autour de 35% d'erreur pour la base de test. C'est normal : la pr√©diction √† partir de la base d'apprentissage, pour les individus de la base d'apprentissage, n'√©tait d√©j√† pas excellente (25% d'erreur).
# Une approche par validation crois√©e permet de tester la robustesse de notre r√©gression par rapport √† l'ajout de donn√©es.

#-----------
# Question 6
#-----------

result = step(fit)
result$coefficients
summary(result)

# On retient les variables ldl, tobacco, famhist et age (mod√®le d'AIC le plus faible).
# Les coefficients les plus significatifs (i.e. au seuil 0.001) sont l'age et la pr√©sence d'ant√©c√©dents familiaux. Ce sont les plus d√©terminants.
# Les autres sont tout de m√™me significatifs au seuil 0.01.