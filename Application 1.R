###########################################
# TP 1 - JÃ©rÃ´me CRÃ‰TIEN - Florent RENUCCI #
# 25 septembre - pour le 15 octobre		  #
###########################################


###########################
# exemples d'instructions #
###########################
# iris
# ncol(iris)
# dim(iris)
# names(iris)
# plot(iris)
# plot(iris,col=c("blue","red","green")[iris$Species])
# mean(iris)
# sd(iris)
# iris[1,]
# iris[,5]
# iris$Species
# tapply(iris$Sepal.Width,iris$Species,mean)
# tapply(iris$Species,iris$Species,length)


#############################################
# Analyse discriminante linÃ©aire prÃ©dictive #
#############################################
rm(list=ls())

#-----------
# Question 1
#-----------
library(MASS)
#-----------
# Question 2
#-----------
help(lda)
model = lda(Species~.,data=iris)
#-----------
# Question 3
#-----------
model
# Prior : il s'agit des probabilitÃ©s a priori d'appartenance Ã  chaque classe (dans une approche bayÃ©sienne). Ici, on n'a pas renseignÃ© d'a priori. La fonciton considÃ¨re donc que l'appartenance Ã  chaque classe est a priori Ã©quiprobable (3 classes => p=1/3).
# Group means : renvoie la moyenne de chaque variable, par classe
# Coefficients of linear discriminants : renvoie les coefficients des vecteurs rÃ©alisant l'analyse discriminante linÃ©aire
# Proportion of trace : renvoie la proportion de la trace (variabilitÃ©) captÃ©e par chaque direction
# Le critÃ¨re de dÃ©cision retenu dans le cadre de l'analyse discriminante linÃ©aire est la maximisation de la variance inter, en ajustant des hyperplans pour classifier (sÃ©parer) les observations.

#-----------
# Question 4
#-----------
plot(model)
# plot(model) permet d'observer la rÃ©partition des observations dans le plan de projection (LD1,LD2) qui maximise la variabilitÃ©. On constate que les trois classes sont assez bien rÃ©parties. En particulier, les setosa sont bien distinctes des deux autres groupes.
# Ceci confirme les valeurs de "proportion of trace" : le 1er vecteur, mÃªme seul, permettrait quand mÃªme de bien sÃ©parer les groupes.

#-----------
# Question 5
#-----------
learning_indices = sample(nrow(iris),0.80*nrow(iris))
# on choisit 80% des lignes, au hasard, qui formeront le learning set

learning_set = iris[learning_indices,]
test_set = iris[-learning_indices,]
# le reste des lignes forment la base de test


#-----------
# Question 6
#-----------
lda_model = lda(Species~.,data=learning_set)
prediction_learning = predict(lda_model,learning_set)
#-----------
# Question 7
#-----------
ConfusionMatrix_learning = table(prediction_learning$class,learning_set$Species)
# Matrice de confusion sur la base d'apprentissage :

# /!\ On ne sait pas a priori, sans regarder l'aide, si on a la confusion matrix ou sa transposÃ©e
# ICI : on a la prÃ©diction en ligne et la cible en colonne
# Matrice de confusion sur la base d'apprentissage :
ConfusionMatrix_learning
# Erreur de prÃ©diction sur la base d'apprentissage :
erreur= 1-sum(diag(ConfusionMatrix_learning))/sum(ConfusionMatrix_learning)

# C'est proche de 0 : c'est une condition nÃ©cessaire non suffisante de fiabilitÃ© du modÃ¨le : la base d'apprentissage permet "de se prÃ©dire elle-mÃªme", ce qui ne signifie pas forcÃ©ment qu'elle peut prÃ©dire les classes d'individus extÃ©rieurs. 

#-----------
# Question 8
#-----------
prediction_test = predict(lda_model,test_set)
ConfusionMatrix_test = table(prediction_test$class,test_set$Species)
# Matrice de confusion sur la base de test :
ConfusionMatrix_test
# Erreur de prÃ©diction sur la base de test :
1-sum(diag(ConfusionMatrix_test))/sum(ConfusionMatrix_test)
# REMARQUES :
# L'erreur de prÃ©diction (en proportion) est comparable pour la base de test et la base d'apprentissage.
# On remarque mÃªme que l'erreur de prÃ©diction est souvent plus faible sur la base de test que sur la base d'apprentissage.
# Ceci n'est pas surprenant : faire des erreurs sur la base d'apprentissage est une bonne chose pour Ã©viter le sur-apprentissage (overfitting).
#-----------
# Question 9
#-----------
# REMARQUES :
# On remarque qu'il ne suffit que de peu d'individus dans la base d'apprentissage pour avoir une erreur de prÃ©diction trÃ¨s faible : mÃªme 30% ou 20% des observations dans la base d'apprentissage permet d'identifier de maniÃ¨re fiable les classes des individus de la base de test. Par ailleurs, il y a rarement des erreurs.
# AprÃ¨s plusieurs tests, on constate que le classiffieur ne se trompe que trÃ¨s rarement (entre 0 et 2 fois selon la base de test)
# En particulier, il ne se trompe jamais pour les setosas, qui sont (comme on l'a vu plus haut) bien sÃ©parÃ©s (gÃ©omÃ©triquement) des deux autres groupes.
# En somme, les donnÃ©es utilisÃ©es ici sont particuliÃ¨rement propres et adaptÃ©es Ã  la mÃ©thode utilisÃ©e.

################################################
# Analyse discriminante quadratique prÃ©dictive #
################################################

#-----------
# Question 1
#-----------
help(qda)
model_qda = qda(Species~.,data=iris)
prediction_qda = predict(model_qda,iris)
ConfusionMatrix_qda = table(prediction_qda$class,iris$Species)
# Matrice de confusion QDA :
ConfusionMatrix_qda
# Erreur de prÃ©diction QDA :
1-sum(diag(ConfusionMatrix_qda))/sum(ConfusionMatrix_qda)

#-----------
# Question 2
#-----------
# RETOUR AU LDA (pour comparaison) :
#-----------------------------------
# prediction LDA :
prediction = predict(model,iris)
ConfusionMatrix_lda  = table(prediction$class,iris$Species)
# Matrice de confusion LDA :
ConfusionMatrix_lda
# Erreur de prÃ©diction LDA :
1-sum(diag(ConfusionMatrix_lda))/sum(ConfusionMatrix_lda)
# REMARQUES :
# Si on effectue une LDA ou une QDA sur l'ensemble des donnÃ©es, on obtient la mÃªme matrice de confusion.
# Pour comparer les deux mÃ©thodes, nous allons donc tester leurs rÃ©sultats plusieurs fois sur des jeux d'apprentissages / test choisis alÃ©atoirement.
# On effectue 1000 tests et on note Ã  chaque fois le nombre d'erreurs de classification pour chaque mÃ©thode.
# (ceci est fait par la portion de code ci-dessous :)
#-------------------------------------------------------
# COMPARAISON LDA/QDA sur des bases apprentissage/test :
#-------------------------------------------------------
N = 1000
lda_errors = rep(0,0.20*nrow(iris))
qda_errors = rep(0,0.20*nrow(iris))
for (k in 1:N) {
	# sets :
	learning_indices = sample(nrow(iris),0.80*nrow(iris))
	learning_set = iris[learning_indices,]
	test_set = iris[-learning_indices,]
	# LDA model :
	lda_model = lda(Species~.,data=learning_set)
	lda_prediction = predict(lda_model,test_set)
	lda_ConfusionMatrix = table(lda_prediction$class,test_set$Species)
	lda_errors[sum(lda_ConfusionMatrix)-sum(diag(lda_ConfusionMatrix))] = lda_errors[sum(lda_ConfusionMatrix)-sum(diag(lda_ConfusionMatrix))] + 1
	# QDA model :
	qda_model = qda(Species~.,data=learning_set)
	qda_prediction = predict(qda_model,test_set)
	qda_ConfusionMatrix = table(qda_prediction$class,test_set$Species)
	qda_errors[sum(qda_ConfusionMatrix)-sum(diag(qda_ConfusionMatrix))] = qda_errors[sum(qda_ConfusionMatrix)-sum(diag(qda_ConfusionMatrix))] + 1
}
plot(lda_errors,type="l",col="red")
lines(qda_errors,col="blue")
title(main="LDA (rouge) / QDA (bleu) : nombre d'erreurs")
legend(c("LDA","QDA"),col=c("red","blue"));
# REMARQUES :
# Dans l'ensemble (sur les 1000 tests rÃ©alisÃ©s), la LDA donne de meilleurs rÃ©sultats que la QDA : pour un nombre d'erreurs donnÃ©, il y a eu plus de rÃ©alisations pour la QDA que pour la LDA.
# Ainsi, il semblerait que la gÃ©omÃ©trie des donnÃ©es soit plutÃ´t adaptÃ©e Ã  un modÃ¨le linÃ©aire que quadratique.
# La comparaison des deux mÃ©thodes se limite bien sÃ»r aux rÃ©sultats obtenus sur les donnÃ©es Ã©tudiÃ©es.

#########################
# RÃ©gression logistique #
#########################
rm(list=ls())

#-----------
# Question 1
#-----------

file = "D:/frenucci/Dropbox/Données/Scolaire/cours/3A/Statistiques et Data-Mining/TP/TP1/SAHeart.txt"

data = read.table(file,sep=",",head=T,row.names=1)
data = data[,-6]
data

# A retrospective sample of males in a heart-disease high-risk region of the Western Cape, South Africa. There are roughly two controls per case of CHD. Many of the CHD positive men have undergone blood pressure reduction treatment and other programs to reduce their risk factors after their CHD event. In some cases the measurements were made after these treatments. These data are taken from a larger dataset, described in  Rousseauw et al, 1983, South African Medical Journal.

# Variables explicatives :
# sbp  	    systolic blood pressure
# tobacco   cumulative tobacco (kg)
# ldl		low densiity lipoprotein cholesterol
# adiposity 
# famhist	family history of heart disease (Present, Absent)
# typea		type-A behavior
# obesity	
# alcohol	current alcohol consumption
# age		age at onset
# chd		response, coronary heart disease

#-----------
# Question 2
#-----------
pairs(data,pch=22,bg=c("red","blue")[unclass(factor(data[,"chd"]))])

# la derniÃ¨re ligne de graphiques nous permet de savoir Ã  quoi correspondent les couleursÂ : les rouges sont les malades.
# On constate que sur tous les graphiques, tous les points sont assez Ã©loignÃ©s pour quâ€™il nâ€™y ait pas un unique facteur explicatif suffisant pour expliquer la maladie.
# Causes visibles Ã  l'oeil nu : grands fumeurs, et gens Ã  forts taux de ldl.

#-----------
# Question 3
#-----------
help(glm)
fit = glm(data$chd~.,data=data,family=binomial)
summary(fit)
#-----------
# Question 4
#-----------
classification = predict.glm(fit,data,type="response")
# classification = predict(fit,data,type="response")
classification = 1*(classification>0.5)
# pour avoir des 0 et 1 Ã  la place de TRUE et FALSE
CM = table(classification,data$chd)
CM
# on peut aussi calculer l'erreur sur la base de test, on trouve 26%
erreur=1-sum(diag(CM))/sum(CM)
# les faux positifs sont au nombre de 77 (Ã©lÃ©ment (1,2) de la matrice de confusion), les faux nÃ©gatifs sont 46 (Ã©lÃ©ment (2,1) de la matrice de confusion)
fauxneg=CM[1,2]/sum(CM)
fauxneg
# 17% de faux nÃ©gatifs
fauxpos=CM[2,1]/sum(CM)
fauxpos
# 10% de faux positifs
# Dans l'ensemble, ces rÃ©sultats ne sont pas trÃ¨s satisfaisants.

#-----------
# Question 5
#-----------

learning_indices = sample(nrow(data),0.75*nrow(data))
# on choisit 75% des lignes, au hasard, qui formeront le learning set
learning_set = data[learning_indices,]
testing_set = data[-learning_indices,]

lda_model = lda(chd~.,data=learning_set)
prediction_learning = predict(lda_model,learning_set)
CM_learning = table(prediction_learning$class,learning_set$chd)

erreur_learning=1-sum(diag(CM_learning))/sum(CM_learning)
fauxneg_learning=CM_learning[1,2]/sum(CM_learning)
fauxpos_learning=CM_learning[2,1]/sum(CM_learning)

# beaucoup d'erreurs : autour de 25% au total, en rÃ©pÃ©tant le test plusieurs fois et en changeant les bases d'apprentissage et de test.

prediction_test = predict(lda_model,testing_set)
CM_test = table(prediction_test$class,testing_set$chd)

erreur_test=1-sum(diag(CM_test))/sum(CM_test)
fauxneg_test=CM_test[1,2]/sum(CM_test)
fauxpos_test=CM_test[2,1]/sum(CM_test)

# On pouvait s'attendre Ã  de tels rÃ©sultats : autour de 35% d'erreur pour la base de test. C'est normal : la prÃ©diction Ã  partir de la base d'apprentissage, pour les individus de la base d'apprentissage, n'Ã©tait dÃ©jÃ  pas excellente (25% d'erreur).
# Une approche par validation croisÃ©e permet de tester la robustesse de notre rÃ©gression par rapport Ã  l'ajout de donnÃ©es.

#-----------
# Question 6
#-----------

result = step(fit)
result$coefficients
summary(result)

# On retient les variables ldl, tobacco, famhist et age (modÃ¨le d'AIC le plus faible).
# Les coefficients les plus significatifs (i.e. au seuil 0.001) sont l'age et la prÃ©sence d'antÃ©cÃ©dents familiaux. Ce sont les plus dÃ©terminants.
# Les autres sont tout de mÃªme significatifs au seuil 0.01.